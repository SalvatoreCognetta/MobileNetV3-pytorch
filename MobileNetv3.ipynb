{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple, List, Optional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass, fields, astuple\n",
    "\n",
    "# For cute animation bar an plots\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b4230a2203e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Check if the GPU is available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 512 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    root_drive  = \"/content/drive/MyDrive/Colab Notebooks/MobileNetV3/\"\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    root_drive = './'\n",
    "\n",
    "spec_small_path = root_drive +  \"specification/mobilenetv3-small.json\"\n",
    "spec_large_path = root_drive +  \"specification/mobilenetv3-large.json\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# MobileNet Specification\n",
    "@dataclass\n",
    "class BNeckSpecification:\n",
    "    '''Class that contains MobileNet specifications.'''\n",
    "    kernel: int\n",
    "    input_size: int\n",
    "    exp_size: int\n",
    "    out_size: int\n",
    "    se: bool\n",
    "    nl: str\n",
    "    stride: nn.Module\n",
    "\n",
    "    # The __post_init__ method, will be the last thing called by __init__.\n",
    "    def __post_init__(self) -> None:\n",
    "        self.kernel     = int(self.kernel)\n",
    "        self.input_size = int(self.input_size)\n",
    "        self.exp_size = int(self.exp_size)\n",
    "        self.out_size = int(self.out_size)\n",
    "        self.se  = bool(self.se)\n",
    "        self.nl  = nn.ReLU(inplace=True) if self.nl == \"relu\" else Hswish(inplace=True)\n",
    "        self.stride = int(self.stride)\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from astuple(self)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_header() -> List[str]:\n",
    "        return [field.name for field in fields(BNeckSpecification)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MobileNetv3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## nn.Modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "class Hsigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True) -> None:\n",
    "        super(Hsigmoid, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return F.relu6(x + 3, inplace=self.inplace) / 6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class Hswish(nn.Module):\n",
    "    def __init__(self, inplace=True) -> None:\n",
    "        super(Hswish, self).__init__()\n",
    "        self.hsigmoid = Hsigmoid(inplace)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return x * self.hsigmoid(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "class SeModule(nn.Module):\n",
    "    def __init__(self, channel, reduction=4) -> None:\n",
    "        super(SeModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.se = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            Hsigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.se(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "\n",
    "# class SeModule(nn.Module):\n",
    "#     def __init__(self, in_size, reduction=4):\n",
    "#         super(SeModule, self).__init__()\n",
    "#         self.se = nn.Sequential(\n",
    "#             nn.AdaptiveAvgPool2d(1),\n",
    "#             nn.Conv2d(in_size, in_size // reduction, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "#             nn.BatchNorm2d(in_size // reduction),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(in_size // reduction, in_size, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "#             nn.BatchNorm2d(in_size),\n",
    "#             hsigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x * self.se(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, spec:BNeckSpecification) -> None:\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.spec = spec\n",
    "        \n",
    "        padding = (spec.kernel - 1) // 2\n",
    "        self.use_res_connect = spec.stride == 1 and spec.input_size == spec.out_size\n",
    "\n",
    "        # PointWise\n",
    "        self.conv2d_pw  = nn.Conv2d(spec.input_size, spec.exp_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(spec.exp_size)\n",
    "        self.non_lin    = spec.nl\n",
    "\n",
    "        # DepthWise\n",
    "        self.conv2d_dw  = nn.Conv2d(spec.exp_size, spec.exp_size, spec.kernel, spec.stride, padding, groups=spec.exp_size,bias=False)\n",
    "        self.squeeze_ex = SeModule(spec.exp_size)\n",
    "\n",
    "        # PointWise-linear\n",
    "        self.conv2d_pw_linear  = nn.Conv2d(spec.exp_size, spec.out_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batch_norm_linear = nn.BatchNorm2d(spec.out_size)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        # PointWise\n",
    "        out = self.conv2d_pw(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.non_lin(out)\n",
    "\n",
    "        # DepthWise\n",
    "        out = self.conv2d_dw(out)\n",
    "        out = self.batch_norm(out)\n",
    "        if self.spec.se: out = self.squeeze_ex(out)\n",
    "        out = self.non_lin(out)\n",
    "\n",
    "        # PointWise-linear\n",
    "        out = self.conv2d_pw_linear(out)\n",
    "        out = self.batch_norm_linear(out)\n",
    "\n",
    "        out = x + out if self.use_res_connect else out\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def conv2d_block(input_size:int, output_size:int, kernel_size:int, stride:int=1) -> nn.Sequential:\n",
    "\treturn nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size, stride, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        Hswish(inplace=True)\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, num_class:int, dropout:float, mode='small') -> None:\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.mode = mode\n",
    "\n",
    "        # Load specifications from file\n",
    "        self.bneck_specs = self.load_bneck_specs()\n",
    "\n",
    "        # Generate all the net blocks\n",
    "        self.net_blocks = [conv2d_block(input_size=3, output_size=16, kernel_size=3, stride=2)]\n",
    "        self.build_bneck_blocks()\n",
    "        self.build_last_layers()\n",
    "\n",
    "        # Transform it nn.Sequential\n",
    "        self.net_blocks = nn.Sequential(*self.net_blocks)\n",
    "\n",
    "        # Building the classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),    # refer to paper section 6\n",
    "            nn.Linear(self.last_channel, self.num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        out = self.net_blocks(x)\n",
    "        # out = out.mean(3).mean(2)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def load_bneck_specs(self) -> List[BNeckSpecification]:\n",
    "        if self.mode == 'small':\n",
    "            self.spec_file = spec_small_path\n",
    "        else:\n",
    "            self.spec_file = spec_large_path\n",
    "        # Load specifications\n",
    "        with open(self.spec_file, \"r\") as spec_f:\n",
    "            data = json.load(spec_f)\n",
    "            bneck_specs = [BNeckSpecification(*spec.values()) for spec in data]\n",
    "        return bneck_specs\n",
    "\n",
    "    def build_bneck_blocks(self) -> None:\n",
    "        # Building mobile blocks\n",
    "        for bneck_spec in self.bneck_specs:\n",
    "            self.net_blocks.append(BottleNeck(bneck_spec))\n",
    "\n",
    "    def build_last_layers(self) -> None:\n",
    "        # Building last layers\n",
    "        input_channel = self.bneck_specs[-1].out_size # Take the last bottleneck output size \n",
    "        if self.mode == 'large':\n",
    "            self.last_conv = 960 # make_divisible(960 * width_mult)\n",
    "            self.last_channel = 1280\n",
    "        elif self.mode == 'small':\n",
    "            self.last_conv = 576 # make_divisible(576 * width_mult)\n",
    "            self.last_channel = 1024\n",
    "        \n",
    "        self.net_blocks.append(conv2d_block(input_channel, self.last_conv, kernel_size=1))\n",
    "        self.net_blocks.append(nn.AdaptiveAvgPool2d(1)) # or  out = F.avg_pool2d(out, 7)\n",
    "        self.net_blocks.append(nn.Conv2d(self.last_conv, self.last_channel, kernel_size=1, stride=1, padding=0))\n",
    "        self.net_blocks.append(Hswish(inplace=True))\n",
    "        # should I add another layer?\n",
    "        # self.net_blocks.append(nn.Conv2d(self.last_channel, self.num_class, kernel_size=1, stride=1, padding=0))\n",
    "        # self.last_channel = self.num_class\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lightning Module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MobileNetV3Module(pl.LightningModule):\n",
    "    def __init__(self, num_classes=1000, dropout=0.8) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        net = MobileNetV3(num_classes, dropout)\n",
    "\n",
    "    def training_step(self):\n",
    "        loss = 0\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}